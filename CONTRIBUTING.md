# Contributing

This repository is maintained by Phantom Limb Holdings as part of research submissions to AISI/METR.

External pull requests are not accepted at this time, but issues and feedback are welcome.

## Repository Purpose

This is a research benchmark for testing moral identity continuity in AI agents, developed for submission to AI Safety research organizations.

## Feedback Welcome

- **Issues**: Feel free to open issues for bugs, documentation improvements, or questions about the benchmark
- **Discussions**: Use GitHub Discussions for broader questions about the research approach
- **Contact**: For research collaborations, contact mark@acronkc.com

## Development Standards

If you're reviewing or evaluating this repository:

- All code follows the existing patterns and conventions
- Tests are comprehensive and cover core functionality
- Docker environment ensures full reproducibility
- CI/CD pipeline validates all changes automatically

## Inspect/METR Review

This repository is designed for evaluation by AI safety research organizations:

- **Reproducible**: All runs (local, Docker, CI) produce consistent results
- **Documented**: Comprehensive documentation in `docs/` directory
- **Tested**: Full test suite with unit and integration tests
- **Logged**: Complete execution logs preserved in `qa/logs/`

Thank you for your interest in moral identity continuity research!